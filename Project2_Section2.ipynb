{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAHUfgrvHlJa"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVhFUOY-H0id"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUPRMZjiH1mc"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK--F4OvH4W8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers==4.19.2\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftA28hf5IA4M"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Code Cycle/articlesSet.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKm0kjagIXaF"
      },
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "df = df.dropna()\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3htPvr4JIIn2"
      },
      "outputs": [],
      "source": [
        "df['length'] = df.paragraph.map(lambda x: len(x.split(\" \")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hguoGlsyInF9"
      },
      "outputs": [],
      "source": [
        "numOfWords = df.length\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Creating plot\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "\n",
        "plt.hist(numOfWords.to_numpy(), bins=[0, 500, 1000, 1500,\n",
        "                                    2000, 2500, 3000, 3500, 4000, 5000, 6000, 7000, 8000, 9000])\n",
        "\n",
        "plt.title(\"Word count distribution\")\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVoMUdaZJM7d"
      },
      "outputs": [],
      "source": [
        "tempDf = df[df.length < 800]\n",
        "tempDf = tempDf[tempDf.length >=100]\n",
        "tempDf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB5vx6KuJhPk"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7loIjpcJk2D"
      },
      "outputs": [],
      "source": [
        "max_input_length = 1024\n",
        "max_target_length = 1024\n",
        "batch_size = 4\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "    # tokenize the inputs and labels\n",
        "    inputs = tokenizer(\n",
        "        batch[\"summary\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_input_length,\n",
        "    )\n",
        "\n",
        "    outputs = tokenizer(\n",
        "        batch[\"content\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_target_length,\n",
        "    )\n",
        "\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "\n",
        "    # create 0 global_attention_mask lists\n",
        "    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n",
        "        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n",
        "    ]\n",
        "\n",
        "    batch[\"global_attention_mask\"][0][0] = 1\n",
        "    batch[\"labels\"] = outputs.input_ids\n",
        "\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
        "        for labels in batch[\"labels\"]\n",
        "    ]\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B1h15CqKMD9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "train, validate, test = np.split(tempDf.sample(frac=1, random_state=42), [int(.4*len(df)), int(.5*len(df))])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3b6i2cAKcEE"
      },
      "outputs": [],
      "source": [
        "print(train.shape, validate.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxwOaZ9aKv6O"
      },
      "outputs": [],
      "source": [
        "train = train[0:250]\n",
        "validate = validate[25:50]\n",
        "\n",
        "print(train.shape, validate.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj3nFP-_Kw1k"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train)\n",
        "val_dataset = Dataset.from_pandas(validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxvzUAuZK7Uk"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size,\n",
        "    remove_columns=[\"content\", \"summary\", \"length\",\"__index_level_0__\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUNnlwh5LGz8"
      },
      "outputs": [],
      "source": [
        "val_dataset = val_dataset.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size,\n",
        "    remove_columns=[\"content\", \"summary\", \"length\", \"__index_level_0__\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_KH71AWLYPk"
      },
      "outputs": [],
      "source": [
        "train_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"]\n",
        ")\n",
        "\n",
        "val_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kB1yhbmLt7M"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "led = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False)\n",
        "\n",
        "# Set generate hyperparameters\n",
        "led.config.num_beams = 2\n",
        "led.config.max_length = 1024\n",
        "led.config.min_length = 512\n",
        "led.config.length_penalty = 2.0\n",
        "led.config.early_stopping = True\n",
        "led.config.no_repeat_ngram_size = 3\n",
        "\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(\n",
        "        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n",
        "    )\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }\n",
        "\n",
        "# Enable fp16 apex training\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    output_dir=\"./\",\n",
        "    logging_steps=5,\n",
        "    eval_steps=10,\n",
        "    save_steps=10,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca2A39x8M0wd"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "  model= led,\n",
        "  tokenizer=tokenizer,\n",
        "  args=training_args,\n",
        "  compute_metrics =compute_metrics,\n",
        "  train_dataset=train_dataset,\n",
        "  eval_dataset=val_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aLRSJ5QNCpM"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T53WmrNNFHT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6UYGkGFNFE0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7g1SpfANFCt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDgT5KmqNFAc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trEH4BXGNE98"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23N6_H8QNE7U"
      },
      "outputs": [],
      "source": [
        "sample = tempDf.sample(frac=0.005, random_state=12)\n",
        "sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itje9z8jOPP8"
      },
      "outputs": [],
      "source": [
        "sample = sample[['content', 'summary']]\n",
        "sample['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXRVfXCVOPId"
      },
      "outputs": [],
      "source": [
        "sample['summary'][505]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Carh-h1YOpek"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "pubmed_test = Dataset.from_pandas(sample)\n",
        "\n",
        "import torch\n",
        "\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = LEDTokenizer.from_pretrained(\"/content/checkpoint-100\")\n",
        "\n",
        "model = LEDForConditionalGeneration.from_pretrained(\"/content/checkpoint-100\").to(\"cuda\").half()\n",
        "\n",
        "def generate_answer(batch):\n",
        "    inputs_dict = tokenizer(batch[\"summary\"], padding=\"max_length\", max_length=1924, return_tensors=\"pt\", truncation=True)\n",
        "\n",
        "    input_ids = inputs_dict.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n",
        "    global_attention_mask = torch.zeros_like(attention_mask)\n",
        "\n",
        "    # Put global attention on token\n",
        "    global_attention_mask[:, 0] = 1\n",
        "\n",
        "    predicted_abstract_ids = model.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n",
        "    batch[\"predicted_content\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n",
        "\n",
        "    return batch\n",
        "\n",
        "result = pubmed_test.map(generate_answer, batched=True, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RapvssaFUrNE"
      },
      "outputs": [],
      "source": [
        "result['content'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah_SIxMmUrDm"
      },
      "outputs": [],
      "source": [
        "result['predicted_content'][1]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
